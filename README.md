# FocusVision ML tools
A place to gather useful links and knowledge 


# General Statistics/Info

Why every statistician should know about [cross-validation] (https://robjhyndman.com/hyndsight/crossvalidation/)

Computational Complexity of learning [algorithms] (https://www.thekerneltrip.com/machine/learning/computational-complexity-learning-algorithms/)

tSNE vs [PCA] (https://www.thekerneltrip.com/statistics/tsne-vs-pca/)

# Neural Networks

## General Info

Deep Leanring [Book](https://www.deeplearningbook.org/)

Micheal Nielson's book for learning about [Neural Networks](http://neuralnetworksanddeeplearning.com/index.html)

The very comprehensive [NN FAQ](http://www.faqs.org/faqs/ai-faq/neural-nets/part1/preamble.html)

Topology of [neural networks](https://ldtopology.wordpress.com/2018/10/21/the-topology-of-neural-networks-part-1-the-generalization-problem/)

More [topology!](https://cs.stanford.edu/people/karpathy/convnetjs//demo/classify2d.html)

## Convolutional NN

Visualizing and understanding Convolutional [networks](https://arxiv.org/pdf/1311.2901.pdf) (pdf)

## Capsule Networks

A good Medium [post](https://medium.com/ai%C2%B3-theory-practice-business/understanding-hintons-capsule-networks-part-i-intuition-b4b559d1159b) explaining how capsule networks work

A git repo for capsule [networks](https://github.com/XifengGuo/CapsNet-Keras)

## Recurrent NN

Understanding [LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)

## Attention 

An introduction to how attention works in [neural networks](http://akosiorek.github.io/ml/2017/10/14/visual-attention.html).

An article predicting the downfall of LSTMs and the rise of [hierarchical attention models](https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0)

Cheng et al 2016 using intra-attention [(self-attention)](https://arxiv.org/pdf/1601.06733.pdf)

A nice summary of different implementations of [attention](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)

# Ensemble Methods

## Gradient Boosting 

A good description of how Gradient Boosting [works](http://explained.ai/gradient-boosting/index.html)

# Word and Document Embedding

## Word2Vec
A useful introduction to [Skip-gram Word2Vec](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)

## Doc2Vec
The gensim implementation of [Doc2vec](https://radimrehurek.com/gensim/models/doc2vec.html)

A doc2vec [tutorial](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb)

A doc2vec analysis on a [IMDB dataset](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-IMDB.ipynb)

# Knowledge Graphs

Link to git repos from the Pujara et al paper on Knowledge graph [identification](https://github.com/linqs/KnowledgeGraphIdentification).

# Generative Adversarial Networks

Goodfellow et al [paper](https://arxiv.org/pdf/1406.2661.pdf)

A short [tutorial](https://skymind.ai/wiki/generative-adversarial-network-gan)

[Notes](http://cs229.stanford.edu/notes/cs229-notes2.pdf) from Andrew Ng's CS229 course on generative learning algorithms

A nice 2018 paper on dissecting [GANs](https://arxiv.org/pdf/1811.10597.pdf)

# Speech Recogtion

Keeping track of the accuracy of different speech recognition approaches, with links to papers. [WER are we?](https://github.com/syhw/wer_are_we)

# General Machine Learning

Arxiv [Sanity](http://www.arxiv-sanity.com/)

How to do [interpretable machine learning](https://christophm.github.io/interpretable-ml-book/)

Some productivity [hacks](https://www.reddit.com/r/MachineLearning/comments/ayzxlt/d_machine_learning_productivity_hacks/)

# Data Structures

Searching [graphs](https://zeroequalsfalse.press/posts/graph-algorithm-data-structure/)

# Data Sources

## Image

Open Images [Datasets](https://storage.googleapis.com/openimages/web/download.html)

## Speech to text

Wall Street [Journal](https://catalog.ldc.upenn.edu/LDC2000T43)

[LibriSpeech](http://www.openslr.org/12/)

[Switchboard](https://catalog.ldc.upenn.edu/LDC97S62)

Mozilla's Common Voice [dataset](https://voice.mozilla.org/en/datasets)

# Machine Learning Journal Club


Tree [LSTM](https://arxiv.org/abs/1503.00075) (Tate)

Video highlight extraction with [robust auto-encoders](https://arxiv.org/abs/1510.01442) (Marius)

[textGAN](https://zhegan27.github.io/Papers/textGAN_nips2016_workshop.pdf) (Mike)

[BooST](https://arxiv.org/abs/1808.03698) (Tate)

[Neural Machine Translation (Attention)](https://arxiv.org/abs/1409.0473) (Marius)

[Semantic Pleonasm Detection](http://www.aclweb.org/anthology/N18-2036) (Arunima)

[Capsule Networks](https://arxiv.org/pdf/1710.09829.pdf) and the [dynamic routing paper](https://openreview.net/pdf?id=HJWLfGWRb) (Tate)

[NLPReViz](https://academic.oup.com/jamia/article/25/1/81/4004729) (Arunima)

YOLO[https://pjreddie.com/media/files/papers/YOLOv3.pdf] (Tate)

[Hierarchical attention](https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf) (Marius)

Style-based [GANs](https://arxiv.org/pdf/1812.04948.pdf) (Tate)

[BERT](https://arxiv.org/pdf/1810.04805.pdf) (Marius/Tate)

Curiosity Driven [Learning](https://pathak22.github.io/large-scale-curiosity/resources/largeScaleCuriosity2018.pdf) (Tate, 2/22/2018)

Deep and Cheap [learning](https://arxiv.org/abs/1608.08225) (Tate, 3/15/2019)

Human object [interaction](https://arxiv.org/abs/1704.07333) (Tate, 3/29/2019)

Review of attention based speech [recognition](https://openreview.net/pdf?id=S1gp9v_jsm) (Tate 4/5/2019)

Improving Language Understanding by Generative [Pre-Training](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf) (Tate 4/12/2019)

Explaining and Harvesting Adversarial [Examples](https://arxiv.org/abs/1412.6572) (Tate 4/27/2019)

Emotional Attention: A Study of Image Sentiment and Visual Attention (Arunima 5/3/2019, pdf posted in slack channel)

Precision/Recall vs [ROC](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0118432) (Tate 5/17/2019)

Locally Linear [Embedding](https://cs.nyu.edu/~roweis/lle/papers/lleintro.pdf) (Tate 5/24/2019)

Fair is Better than Sensational:Man is to Doctor as Woman is to [Doctor](https://arxiv.org/abs/1905.09866) (Tate 5/31/2019)

Hybrid CTC-Attention based End-to-End Speech Recognition using Subword [Units](https://arxiv.org/abs/1807.04978) (Tate 6/7/2019)

RWTH ASR Systems for LibriSpeech: Hybrid vs Attention -- w/o Data [Augmentation](https://arxiv.org/abs/1905.03072) (Tate 6/14/2019)

DeepLOB: Deep Convolutional Neural Networks for Limit Order [Books](https://arxiv.org/pdf/1808.03668.pdf) (Marius 6/21/2019)

Geometric Understanding of Deep [Learning](https://arxiv.org/abs/1805.10451) (Mike P 6/28/2019)

Hidden Technical Debt in Machine Learning [Systems](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems) (Tate 7/12/2019)

Detecting Adversarial [Examples](https://arxiv.org/abs/1907.02957) (Tate 7/19/2018)

AI simulation of [Universe](https://www.simonsfoundation.org/2019/06/26/ai-universe-simulation/) (Mike P 7/26/2019)

Estimating the success of re-identifications in incomplete [datasets](https://www.nature.com/articles/s41467-019-10933-3) (Tate 8/2/2019)

Overview of GMM/HMM for speech [recognition](http://www.iitg.ac.in/samudravijaya/tutorialSlides/gmmHmmTutoChiefWiSSAP09.pdf) (Mike P 8/16/2019)

Listen Attend [Spell](https://arxiv.org/abs/1508.01211) (Tate 8/23/2019)

Strategy For and With [AI](https://focusvision.slack.com/archives/CFPCKTTGT/p1565987251000700?thread_ts=1565907585.001000&cid=CFPCKTTGT) (Mike K 8/30/2019)

On Extractive and Abstractive Neural Document Summarization with Transformer Language [Models](https://arxiv.org/abs/1909.03186) (Tate 9/13/2019)
